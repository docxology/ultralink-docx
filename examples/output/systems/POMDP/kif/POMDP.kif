;; UltraLink Knowledge Interchange Format (KIF) Export
;; Generated: 2025-03-09T18:52:14.757Z

;; Meta-knowledge
(= (creationDate UltraLinkExport) "2025-03-09T18:52:14.757Z")
(= (entityCount UltraLinkExport) 9)
(= (relationshipCount UltraLinkExport) 16)

;; Functions
(deffunction relationshipCount (?x) (length ?kb.relationships))

;; Rules
(defrule entity-attributes-rule
    "A rule to infer additional attributes for entities based on their type"
    (instance ?entity ?type)
    =>
    (if (eq ?type Person)
        then (assert (isAgent ?entity true))))

(forall (?x ?y)
    (=> (and (adapts_to ?x ?y) (> (efficiency-adapts_to ?x ?y) 0.8))
        (well-adapted ?x ?y)))

;; Entities and their attributes
(instance pomdp_model Model)
(name pomdp_model "Active Inference POMDP Model")
(description pomdp_model "A Partially Observable Markov Decision Process implemented with Active Inference")
(domain pomdp_model "computational_neuroscience")
(model_type pomdp_model "discrete")
(discount_factor pomdp_model 0.95)
(horizon pomdp_model 10)
(time_steps pomdp_model 100)

(instance observation_space Space)
(name observation_space "Observation Space")
(symbol observation_space "o")
(dimensions observation_space "[3,1]")
(description observation_space "The set of possible observations an agent can perceive")
(observations observation_space "[{\"id\":\"o1\",\"name\":\"Observation 1\",\"description\":\"Low sensory input\"},{\"id\":\"o2\",\"name\":\"Observation 2\",\"description\":\"Medium sensory input\"},{\"id\":\"o3\",\"name\":\"Observation 3\",\"description\":\"High sensory input\"}]")

(instance state_space Space)
(name state_space "Latent State Space")
(symbol state_space "s")
(dimensions state_space "[5,1]")
(description state_space "The set of possible hidden states the environment can be in")
(states state_space "[{\"id\":\"s1\",\"name\":\"State 1\",\"description\":\"Very low state value\"},{\"id\":\"s2\",\"name\":\"State 2\",\"description\":\"Low state value\"},{\"id\":\"s3\",\"name\":\"State 3\",\"description\":\"Medium state value\"},{\"id\":\"s4\",\"name\":\"State 4\",\"description\":\"High state value\"},{\"id\":\"s5\",\"name\":\"State 5\",\"description\":\"Very high state value\"}]")

(instance action_space Space)
(name action_space "Action Space")
(symbol action_space "a")
(dimensions action_space "[2,1]")
(description action_space "The set of possible actions an agent can take")
(actions action_space "[{\"id\":\"a1\",\"name\":\"Action 1\",\"description\":\"Decrease value\"},{\"id\":\"a2\",\"name\":\"Action 2\",\"description\":\"Increase value\"}]")

(instance a_matrix Matrix)
(name a_matrix "Observation Likelihood Matrix")
(symbol a_matrix "A")
(dimensions a_matrix "[3,5]")
(description a_matrix "Maps hidden states to observations (likelihood mapping)")
(matrix_type a_matrix "likelihood")
(matrix_data a_matrix "[[0.8,0.3,0.1,0,0],[0.2,0.6,0.7,0.3,0.1],[0,0.1,0.2,0.7,0.9]]")
(precision a_matrix 0.9)
(column_labels a_matrix "[\"s1\",\"s2\",\"s3\",\"s4\",\"s5\"]")
(row_labels a_matrix "[\"o1\",\"o2\",\"o3\"]")

(instance b_matrix Matrix)
(name b_matrix "State Transition Matrix")
(symbol b_matrix "B")
(dimensions b_matrix "[5,5,2]")
(description b_matrix "Defines the dynamics of state transitions based on actions")
(matrix_type b_matrix "transition")
(matrix_data b_matrix "[[[0.9,0.2,0,0,0],[0.1,0.7,0.2,0,0],[0,0.1,0.7,0.2,0],[0,0,0.1,0.7,0.1],[0,0,0,0.1,0.9]],[[0.9,0.1,0,0,0],[0.1,0.7,0.1,0,0],[0,0.2,0.7,0.1,0],[0,0,0.2,0.7,0.1],[0,0,0,0.2,0.9]]]")
(action_labels b_matrix "[\"a1\",\"a2\"]")
(column_labels b_matrix "[\"s1\",\"s2\",\"s3\",\"s4\",\"s5\"]")
(row_labels b_matrix "[\"s1\",\"s2\",\"s3\",\"s4\",\"s5\"]")

(instance c_matrix Matrix)
(name c_matrix "Preference Matrix")
(symbol c_matrix "C")
(dimensions c_matrix "[3,1]")
(description c_matrix "Specifies the agent preferences over observations (as log probabilities)")
(matrix_type c_matrix "preference")
(matrix_data c_matrix "[[-3],[0],[3]]")
(row_labels c_matrix "[\"o1\",\"o2\",\"o3\"]")
(precision c_matrix 1)

(instance d_matrix Matrix)
(name d_matrix "Initial State Prior")
(symbol d_matrix "D")
(dimensions d_matrix "[5,1]")
(description d_matrix "Defines the prior distribution over initial states")
(matrix_type d_matrix "prior")
(matrix_data d_matrix "[[0.2],[0.2],[0.4],[0.1],[0.1]]")
(row_labels d_matrix "[\"s1\",\"s2\",\"s3\",\"s4\",\"s5\"]")

(instance e_matrix Matrix)
(name e_matrix "Policy Prior")
(symbol e_matrix "E")
(dimensions e_matrix "[2,1]")
(description e_matrix "Defines the prior distribution over policies/actions")
(matrix_type e_matrix "policy_prior")
(matrix_data e_matrix "[[0.5],[0.5]]")
(row_labels e_matrix "[\"a1\",\"a2\"]")

;; Relationships
(includes pomdp_model observation_space)

(includes pomdp_model state_space)

(includes pomdp_model action_space)

(includes pomdp_model a_matrix)

(includes pomdp_model b_matrix)

(includes pomdp_model c_matrix)

(includes pomdp_model d_matrix)

(includes pomdp_model e_matrix)

(maps_from a_matrix observation_space)

(maps_to a_matrix state_space)

(maps_from b_matrix state_space)

(maps_to b_matrix state_space)

(conditioned_on b_matrix action_space)

(evaluates c_matrix observation_space)

(distributes_over d_matrix state_space)

(distributes_over e_matrix action_space)

