{
  "json": {
    "metadata": {
      "exportDate": "2025-03-09T18:52:14.758Z",
      "entityCount": 9,
      "relationshipCount": 16
    },
    "entities": [
      {
        "id": "pomdp_model",
        "type": "model",
        "attributes": {
          "name": "Active Inference POMDP Model",
          "description": "A Partially Observable Markov Decision Process implemented with Active Inference",
          "domain": "computational_neuroscience",
          "model_type": "discrete",
          "discount_factor": 0.95,
          "horizon": 10,
          "time_steps": 100
        }
      },
      {
        "id": "observation_space",
        "type": "space",
        "attributes": {
          "name": "Observation Space",
          "symbol": "o",
          "dimensions": [
            3,
            1
          ],
          "description": "The set of possible observations an agent can perceive",
          "observations": [
            {
              "id": "o1",
              "name": "Observation 1",
              "description": "Low sensory input"
            },
            {
              "id": "o2",
              "name": "Observation 2",
              "description": "Medium sensory input"
            },
            {
              "id": "o3",
              "name": "Observation 3",
              "description": "High sensory input"
            }
          ]
        }
      },
      {
        "id": "state_space",
        "type": "space",
        "attributes": {
          "name": "Latent State Space",
          "symbol": "s",
          "dimensions": [
            5,
            1
          ],
          "description": "The set of possible hidden states the environment can be in",
          "states": [
            {
              "id": "s1",
              "name": "State 1",
              "description": "Very low state value"
            },
            {
              "id": "s2",
              "name": "State 2",
              "description": "Low state value"
            },
            {
              "id": "s3",
              "name": "State 3",
              "description": "Medium state value"
            },
            {
              "id": "s4",
              "name": "State 4",
              "description": "High state value"
            },
            {
              "id": "s5",
              "name": "State 5",
              "description": "Very high state value"
            }
          ]
        }
      },
      {
        "id": "action_space",
        "type": "space",
        "attributes": {
          "name": "Action Space",
          "symbol": "a",
          "dimensions": [
            2,
            1
          ],
          "description": "The set of possible actions an agent can take",
          "actions": [
            {
              "id": "a1",
              "name": "Action 1",
              "description": "Decrease value"
            },
            {
              "id": "a2",
              "name": "Action 2",
              "description": "Increase value"
            }
          ]
        }
      },
      {
        "id": "a_matrix",
        "type": "matrix",
        "attributes": {
          "name": "Observation Likelihood Matrix",
          "symbol": "A",
          "dimensions": [
            3,
            5
          ],
          "description": "Maps hidden states to observations (likelihood mapping)",
          "matrix_type": "likelihood",
          "matrix_data": [
            [
              0.8,
              0.3,
              0.1,
              0,
              0
            ],
            [
              0.2,
              0.6,
              0.7,
              0.3,
              0.1
            ],
            [
              0,
              0.1,
              0.2,
              0.7,
              0.9
            ]
          ],
          "precision": 0.9,
          "column_labels": [
            "s1",
            "s2",
            "s3",
            "s4",
            "s5"
          ],
          "row_labels": [
            "o1",
            "o2",
            "o3"
          ]
        }
      },
      {
        "id": "b_matrix",
        "type": "matrix",
        "attributes": {
          "name": "State Transition Matrix",
          "symbol": "B",
          "dimensions": [
            5,
            5,
            2
          ],
          "description": "Defines the dynamics of state transitions based on actions",
          "matrix_type": "transition",
          "matrix_data": [
            [
              [
                0.9,
                0.2,
                0,
                0,
                0
              ],
              [
                0.1,
                0.7,
                0.2,
                0,
                0
              ],
              [
                0,
                0.1,
                0.7,
                0.2,
                0
              ],
              [
                0,
                0,
                0.1,
                0.7,
                0.1
              ],
              [
                0,
                0,
                0,
                0.1,
                0.9
              ]
            ],
            [
              [
                0.9,
                0.1,
                0,
                0,
                0
              ],
              [
                0.1,
                0.7,
                0.1,
                0,
                0
              ],
              [
                0,
                0.2,
                0.7,
                0.1,
                0
              ],
              [
                0,
                0,
                0.2,
                0.7,
                0.1
              ],
              [
                0,
                0,
                0,
                0.2,
                0.9
              ]
            ]
          ],
          "action_labels": [
            "a1",
            "a2"
          ],
          "column_labels": [
            "s1",
            "s2",
            "s3",
            "s4",
            "s5"
          ],
          "row_labels": [
            "s1",
            "s2",
            "s3",
            "s4",
            "s5"
          ]
        }
      },
      {
        "id": "c_matrix",
        "type": "matrix",
        "attributes": {
          "name": "Preference Matrix",
          "symbol": "C",
          "dimensions": [
            3,
            1
          ],
          "description": "Specifies the agent preferences over observations (as log probabilities)",
          "matrix_type": "preference",
          "matrix_data": [
            [
              -3
            ],
            [
              0
            ],
            [
              3
            ]
          ],
          "row_labels": [
            "o1",
            "o2",
            "o3"
          ],
          "precision": 1
        }
      },
      {
        "id": "d_matrix",
        "type": "matrix",
        "attributes": {
          "name": "Initial State Prior",
          "symbol": "D",
          "dimensions": [
            5,
            1
          ],
          "description": "Defines the prior distribution over initial states",
          "matrix_type": "prior",
          "matrix_data": [
            [
              0.2
            ],
            [
              0.2
            ],
            [
              0.4
            ],
            [
              0.1
            ],
            [
              0.1
            ]
          ],
          "row_labels": [
            "s1",
            "s2",
            "s3",
            "s4",
            "s5"
          ]
        }
      },
      {
        "id": "e_matrix",
        "type": "matrix",
        "attributes": {
          "name": "Policy Prior",
          "symbol": "E",
          "dimensions": [
            2,
            1
          ],
          "description": "Defines the prior distribution over policies/actions",
          "matrix_type": "policy_prior",
          "matrix_data": [
            [
              0.5
            ],
            [
              0.5
            ]
          ],
          "row_labels": [
            "a1",
            "a2"
          ]
        }
      }
    ],
    "relationships": [
      {
        "source": "pomdp_model",
        "target": "observation_space",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "state_space",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "action_space",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "a_matrix",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "b_matrix",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "c_matrix",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "d_matrix",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "pomdp_model",
        "target": "e_matrix",
        "type": "includes",
        "attributes": {}
      },
      {
        "source": "a_matrix",
        "target": "observation_space",
        "type": "maps_from",
        "attributes": {}
      },
      {
        "source": "a_matrix",
        "target": "state_space",
        "type": "maps_to",
        "attributes": {}
      },
      {
        "source": "b_matrix",
        "target": "state_space",
        "type": "maps_from",
        "attributes": {}
      },
      {
        "source": "b_matrix",
        "target": "state_space",
        "type": "maps_to",
        "attributes": {}
      },
      {
        "source": "b_matrix",
        "target": "action_space",
        "type": "conditioned_on",
        "attributes": {}
      },
      {
        "source": "c_matrix",
        "target": "observation_space",
        "type": "evaluates",
        "attributes": {}
      },
      {
        "source": "d_matrix",
        "target": "state_space",
        "type": "distributes_over",
        "attributes": {}
      },
      {
        "source": "e_matrix",
        "target": "action_space",
        "type": "distributes_over",
        "attributes": {}
      }
    ]
  },
  "csv": {
    "entities.csv": "id,type,name,description,domain,model_type,discount_factor,horizon,time_steps,symbol,dimensions,observations,states,actions,matrix_type,matrix_data,precision,column_labels,row_labels,action_labels\npomdp_model,model,Active Inference POMDP Model,A Partially Observable Markov Decision Process implemented with Active Inference,computational_neuroscience,discrete,0.95,10,100,,,,,,,,,,,\nobservation_space,space,Observation Space,The set of possible observations an agent can perceive,,,,,,o,3,1,[object Object],[object Object],[object Object],,,,,,,,\nstate_space,space,Latent State Space,The set of possible hidden states the environment can be in,,,,,,s,5,1,,[object Object],[object Object],[object Object],[object Object],[object Object],,,,,,,\naction_space,space,Action Space,The set of possible actions an agent can take,,,,,,a,2,1,,,[object Object],[object Object],,,,,,\na_matrix,matrix,Observation Likelihood Matrix,Maps hidden states to observations (likelihood mapping),,,,,,A,3,5,,,,likelihood,0.8,0.3,0.1,0,0,0.2,0.6,0.7,0.3,0.1,0,0.1,0.2,0.7,0.9,0.9,s1,s2,s3,s4,s5,o1,o2,o3,\nb_matrix,matrix,State Transition Matrix,Defines the dynamics of state transitions based on actions,,,,,,B,5,5,2,,,,transition,0.9,0.2,0,0,0,0.1,0.7,0.2,0,0,0,0.1,0.7,0.2,0,0,0,0.1,0.7,0.1,0,0,0,0.1,0.9,0.9,0.1,0,0,0,0.1,0.7,0.1,0,0,0,0.2,0.7,0.1,0,0,0,0.2,0.7,0.1,0,0,0,0.2,0.9,,s1,s2,s3,s4,s5,s1,s2,s3,s4,s5,a1,a2\nc_matrix,matrix,Preference Matrix,Specifies the agent preferences over observations (as log probabilities),,,,,,C,3,1,,,,preference,-3,0,3,1,,o1,o2,o3,\nd_matrix,matrix,Initial State Prior,Defines the prior distribution over initial states,,,,,,D,5,1,,,,prior,0.2,0.2,0.4,0.1,0.1,,,s1,s2,s3,s4,s5,\ne_matrix,matrix,Policy Prior,Defines the prior distribution over policies/actions,,,,,,E,2,1,,,,policy_prior,0.5,0.5,,,a1,a2,",
    "relationships.csv": "source,target,type\npomdp_model,observation_space,includes\npomdp_model,state_space,includes\npomdp_model,action_space,includes\npomdp_model,a_matrix,includes\npomdp_model,b_matrix,includes\npomdp_model,c_matrix,includes\npomdp_model,d_matrix,includes\npomdp_model,e_matrix,includes\na_matrix,observation_space,maps_from\na_matrix,state_space,maps_to\nb_matrix,state_space,maps_from\nb_matrix,state_space,maps_to\nb_matrix,action_space,conditioned_on\nc_matrix,observation_space,evaluates\nd_matrix,state_space,distributes_over\ne_matrix,action_space,distributes_over",
    "entities": "id,type,name,description,domain,model_type,discount_factor,horizon,time_steps,symbol,dimensions,observations,states,actions,matrix_type,matrix_data,precision,column_labels,row_labels,action_labels\npomdp_model,model,Active Inference POMDP Model,A Partially Observable Markov Decision Process implemented with Active Inference,computational_neuroscience,discrete,0.95,10,100,,,,,,,,,,,\nobservation_space,space,Observation Space,The set of possible observations an agent can perceive,,,,,,o,3,1,[object Object],[object Object],[object Object],,,,,,,,\nstate_space,space,Latent State Space,The set of possible hidden states the environment can be in,,,,,,s,5,1,,[object Object],[object Object],[object Object],[object Object],[object Object],,,,,,,\naction_space,space,Action Space,The set of possible actions an agent can take,,,,,,a,2,1,,,[object Object],[object Object],,,,,,\na_matrix,matrix,Observation Likelihood Matrix,Maps hidden states to observations (likelihood mapping),,,,,,A,3,5,,,,likelihood,0.8,0.3,0.1,0,0,0.2,0.6,0.7,0.3,0.1,0,0.1,0.2,0.7,0.9,0.9,s1,s2,s3,s4,s5,o1,o2,o3,\nb_matrix,matrix,State Transition Matrix,Defines the dynamics of state transitions based on actions,,,,,,B,5,5,2,,,,transition,0.9,0.2,0,0,0,0.1,0.7,0.2,0,0,0,0.1,0.7,0.2,0,0,0,0.1,0.7,0.1,0,0,0,0.1,0.9,0.9,0.1,0,0,0,0.1,0.7,0.1,0,0,0,0.2,0.7,0.1,0,0,0,0.2,0.7,0.1,0,0,0,0.2,0.9,,s1,s2,s3,s4,s5,s1,s2,s3,s4,s5,a1,a2\nc_matrix,matrix,Preference Matrix,Specifies the agent preferences over observations (as log probabilities),,,,,,C,3,1,,,,preference,-3,0,3,1,,o1,o2,o3,\nd_matrix,matrix,Initial State Prior,Defines the prior distribution over initial states,,,,,,D,5,1,,,,prior,0.2,0.2,0.4,0.1,0.1,,,s1,s2,s3,s4,s5,\ne_matrix,matrix,Policy Prior,Defines the prior distribution over policies/actions,,,,,,E,2,1,,,,policy_prior,0.5,0.5,,,a1,a2,",
    "relationships": "source,target,type\npomdp_model,observation_space,includes\npomdp_model,state_space,includes\npomdp_model,action_space,includes\npomdp_model,a_matrix,includes\npomdp_model,b_matrix,includes\npomdp_model,c_matrix,includes\npomdp_model,d_matrix,includes\npomdp_model,e_matrix,includes\na_matrix,observation_space,maps_from\na_matrix,state_space,maps_to\nb_matrix,state_space,maps_from\nb_matrix,state_space,maps_to\nb_matrix,action_space,conditioned_on\nc_matrix,observation_space,evaluates\nd_matrix,state_space,distributes_over\ne_matrix,action_space,distributes_over"
  },
  "graphml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns\n         http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">\n  <graph id=\"G\" edgedefault=\"directed\">\n    <!-- Node attribute keys -->\n    <key id=\"type\" for=\"node\" attr.name=\"type\" attr.type=\"string\"/>\n    <key id=\"name\" for=\"node\" attr.name=\"name\" attr.type=\"string\"/>\n    <key id=\"description\" for=\"node\" attr.name=\"description\" attr.type=\"string\"/>\n    <key id=\"domain\" for=\"node\" attr.name=\"domain\" attr.type=\"string\"/>\n    <key id=\"model_type\" for=\"node\" attr.name=\"model_type\" attr.type=\"string\"/>\n    <key id=\"discount_factor\" for=\"node\" attr.name=\"discount_factor\" attr.type=\"string\"/>\n    <key id=\"horizon\" for=\"node\" attr.name=\"horizon\" attr.type=\"string\"/>\n    <key id=\"time_steps\" for=\"node\" attr.name=\"time_steps\" attr.type=\"string\"/>\n    <key id=\"symbol\" for=\"node\" attr.name=\"symbol\" attr.type=\"string\"/>\n    <key id=\"dimensions\" for=\"node\" attr.name=\"dimensions\" attr.type=\"string\"/>\n    <key id=\"observations\" for=\"node\" attr.name=\"observations\" attr.type=\"string\"/>\n    <key id=\"states\" for=\"node\" attr.name=\"states\" attr.type=\"string\"/>\n    <key id=\"actions\" for=\"node\" attr.name=\"actions\" attr.type=\"string\"/>\n    <key id=\"matrix_type\" for=\"node\" attr.name=\"matrix_type\" attr.type=\"string\"/>\n    <key id=\"matrix_data\" for=\"node\" attr.name=\"matrix_data\" attr.type=\"string\"/>\n    <key id=\"precision\" for=\"node\" attr.name=\"precision\" attr.type=\"string\"/>\n    <key id=\"column_labels\" for=\"node\" attr.name=\"column_labels\" attr.type=\"string\"/>\n    <key id=\"row_labels\" for=\"node\" attr.name=\"row_labels\" attr.type=\"string\"/>\n    <key id=\"action_labels\" for=\"node\" attr.name=\"action_labels\" attr.type=\"string\"/>\n    <!-- Edge attribute keys -->\n    <key id=\"relationship_type\" for=\"edge\" attr.name=\"type\" attr.type=\"string\"/>\n    <node id=\"pomdp_model\">\n      <data key=\"type\">model</data>\n      <data key=\"name\">Active Inference POMDP Model</data>\n      <data key=\"description\">A Partially Observable Markov Decision Process implemented with Active Inference</data>\n      <data key=\"domain\">computational_neuroscience</data>\n      <data key=\"model_type\">discrete</data>\n      <data key=\"discount_factor\">0.95</data>\n      <data key=\"horizon\">10</data>\n      <data key=\"time_steps\">100</data>\n    </node>\n    <node id=\"observation_space\">\n      <data key=\"type\">space</data>\n      <data key=\"name\">Observation Space</data>\n      <data key=\"symbol\">o</data>\n      <data key=\"dimensions\">3,1</data>\n      <data key=\"description\">The set of possible observations an agent can perceive</data>\n      <data key=\"observations\">[object Object],[object Object],[object Object]</data>\n    </node>\n    <node id=\"state_space\">\n      <data key=\"type\">space</data>\n      <data key=\"name\">Latent State Space</data>\n      <data key=\"symbol\">s</data>\n      <data key=\"dimensions\">5,1</data>\n      <data key=\"description\">The set of possible hidden states the environment can be in</data>\n      <data key=\"states\">[object Object],[object Object],[object Object],[object Object],[object Object]</data>\n    </node>\n    <node id=\"action_space\">\n      <data key=\"type\">space</data>\n      <data key=\"name\">Action Space</data>\n      <data key=\"symbol\">a</data>\n      <data key=\"dimensions\">2,1</data>\n      <data key=\"description\">The set of possible actions an agent can take</data>\n      <data key=\"actions\">[object Object],[object Object]</data>\n    </node>\n    <node id=\"a_matrix\">\n      <data key=\"type\">matrix</data>\n      <data key=\"name\">Observation Likelihood Matrix</data>\n      <data key=\"symbol\">A</data>\n      <data key=\"dimensions\">3,5</data>\n      <data key=\"description\">Maps hidden states to observations (likelihood mapping)</data>\n      <data key=\"matrix_type\">likelihood</data>\n      <data key=\"matrix_data\">0.8,0.3,0.1,0,0,0.2,0.6,0.7,0.3,0.1,0,0.1,0.2,0.7,0.9</data>\n      <data key=\"precision\">0.9</data>\n      <data key=\"column_labels\">s1,s2,s3,s4,s5</data>\n      <data key=\"row_labels\">o1,o2,o3</data>\n    </node>\n    <node id=\"b_matrix\">\n      <data key=\"type\">matrix</data>\n      <data key=\"name\">State Transition Matrix</data>\n      <data key=\"symbol\">B</data>\n      <data key=\"dimensions\">5,5,2</data>\n      <data key=\"description\">Defines the dynamics of state transitions based on actions</data>\n      <data key=\"matrix_type\">transition</data>\n      <data key=\"matrix_data\">0.9,0.2,0,0,0,0.1,0.7,0.2,0,0,0,0.1,0.7,0.2,0,0,0,0.1,0.7,0.1,0,0,0,0.1,0.9,0.9,0.1,0,0,0,0.1,0.7,0.1,0,0,0,0.2,0.7,0.1,0,0,0,0.2,0.7,0.1,0,0,0,0.2,0.9</data>\n      <data key=\"action_labels\">a1,a2</data>\n      <data key=\"column_labels\">s1,s2,s3,s4,s5</data>\n      <data key=\"row_labels\">s1,s2,s3,s4,s5</data>\n    </node>\n    <node id=\"c_matrix\">\n      <data key=\"type\">matrix</data>\n      <data key=\"name\">Preference Matrix</data>\n      <data key=\"symbol\">C</data>\n      <data key=\"dimensions\">3,1</data>\n      <data key=\"description\">Specifies the agent preferences over observations (as log probabilities)</data>\n      <data key=\"matrix_type\">preference</data>\n      <data key=\"matrix_data\">-3,0,3</data>\n      <data key=\"row_labels\">o1,o2,o3</data>\n      <data key=\"precision\">1</data>\n    </node>\n    <node id=\"d_matrix\">\n      <data key=\"type\">matrix</data>\n      <data key=\"name\">Initial State Prior</data>\n      <data key=\"symbol\">D</data>\n      <data key=\"dimensions\">5,1</data>\n      <data key=\"description\">Defines the prior distribution over initial states</data>\n      <data key=\"matrix_type\">prior</data>\n      <data key=\"matrix_data\">0.2,0.2,0.4,0.1,0.1</data>\n      <data key=\"row_labels\">s1,s2,s3,s4,s5</data>\n    </node>\n    <node id=\"e_matrix\">\n      <data key=\"type\">matrix</data>\n      <data key=\"name\">Policy Prior</data>\n      <data key=\"symbol\">E</data>\n      <data key=\"dimensions\">2,1</data>\n      <data key=\"description\">Defines the prior distribution over policies/actions</data>\n      <data key=\"matrix_type\">policy_prior</data>\n      <data key=\"matrix_data\">0.5,0.5</data>\n      <data key=\"row_labels\">a1,a2</data>\n    </node>\n    <edge source=\"pomdp_model\" target=\"observation_space\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"state_space\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"action_space\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"a_matrix\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"b_matrix\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"c_matrix\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"d_matrix\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"pomdp_model\" target=\"e_matrix\">\n      <data key=\"relationship_type\">includes</data>\n    </edge>\n    <edge source=\"a_matrix\" target=\"observation_space\">\n      <data key=\"relationship_type\">maps_from</data>\n    </edge>\n    <edge source=\"a_matrix\" target=\"state_space\">\n      <data key=\"relationship_type\">maps_to</data>\n    </edge>\n    <edge source=\"b_matrix\" target=\"state_space\">\n      <data key=\"relationship_type\">maps_from</data>\n    </edge>\n    <edge source=\"b_matrix\" target=\"state_space\">\n      <data key=\"relationship_type\">maps_to</data>\n    </edge>\n    <edge source=\"b_matrix\" target=\"action_space\">\n      <data key=\"relationship_type\">conditioned_on</data>\n    </edge>\n    <edge source=\"c_matrix\" target=\"observation_space\">\n      <data key=\"relationship_type\">evaluates</data>\n    </edge>\n    <edge source=\"d_matrix\" target=\"state_space\">\n      <data key=\"relationship_type\">distributes_over</data>\n    </edge>\n    <edge source=\"e_matrix\" target=\"action_space\">\n      <data key=\"relationship_type\">distributes_over</data>\n    </edge>\n  </graph>\n</graphml>",
  "kif": ";; UltraLink Knowledge Interchange Format (KIF) Export\n;; Generated: 2025-03-09T18:52:14.758Z\n\n;; Meta-knowledge\n(= (creationDate UltraLinkExport) \"2025-03-09T18:52:14.758Z\")\n(= (entityCount UltraLinkExport) 9)\n(= (relationshipCount UltraLinkExport) 16)\n\n;; Functions\n(deffunction relationshipCount (?x) (length ?kb.relationships))\n\n;; Rules\n(defrule entity-attributes-rule\n    \"A rule to infer additional attributes for entities based on their type\"\n    (instance ?entity ?type)\n    =>\n    (if (eq ?type Person)\n        then (assert (isAgent ?entity true))))\n\n(forall (?x ?y)\n    (=> (and (adapts_to ?x ?y) (> (efficiency-adapts_to ?x ?y) 0.8))\n        (well-adapted ?x ?y)))\n\n;; Entities and their attributes\n(instance pomdp_model Model)\n(name pomdp_model \"Active Inference POMDP Model\")\n(description pomdp_model \"A Partially Observable Markov Decision Process implemented with Active Inference\")\n(domain pomdp_model \"computational_neuroscience\")\n(model_type pomdp_model \"discrete\")\n(discount_factor pomdp_model 0.95)\n(horizon pomdp_model 10)\n(time_steps pomdp_model 100)\n\n(instance observation_space Space)\n(name observation_space \"Observation Space\")\n(symbol observation_space \"o\")\n(dimensions observation_space \"[3,1]\")\n(description observation_space \"The set of possible observations an agent can perceive\")\n(observations observation_space \"[{\\\"id\\\":\\\"o1\\\",\\\"name\\\":\\\"Observation 1\\\",\\\"description\\\":\\\"Low sensory input\\\"},{\\\"id\\\":\\\"o2\\\",\\\"name\\\":\\\"Observation 2\\\",\\\"description\\\":\\\"Medium sensory input\\\"},{\\\"id\\\":\\\"o3\\\",\\\"name\\\":\\\"Observation 3\\\",\\\"description\\\":\\\"High sensory input\\\"}]\")\n\n(instance state_space Space)\n(name state_space \"Latent State Space\")\n(symbol state_space \"s\")\n(dimensions state_space \"[5,1]\")\n(description state_space \"The set of possible hidden states the environment can be in\")\n(states state_space \"[{\\\"id\\\":\\\"s1\\\",\\\"name\\\":\\\"State 1\\\",\\\"description\\\":\\\"Very low state value\\\"},{\\\"id\\\":\\\"s2\\\",\\\"name\\\":\\\"State 2\\\",\\\"description\\\":\\\"Low state value\\\"},{\\\"id\\\":\\\"s3\\\",\\\"name\\\":\\\"State 3\\\",\\\"description\\\":\\\"Medium state value\\\"},{\\\"id\\\":\\\"s4\\\",\\\"name\\\":\\\"State 4\\\",\\\"description\\\":\\\"High state value\\\"},{\\\"id\\\":\\\"s5\\\",\\\"name\\\":\\\"State 5\\\",\\\"description\\\":\\\"Very high state value\\\"}]\")\n\n(instance action_space Space)\n(name action_space \"Action Space\")\n(symbol action_space \"a\")\n(dimensions action_space \"[2,1]\")\n(description action_space \"The set of possible actions an agent can take\")\n(actions action_space \"[{\\\"id\\\":\\\"a1\\\",\\\"name\\\":\\\"Action 1\\\",\\\"description\\\":\\\"Decrease value\\\"},{\\\"id\\\":\\\"a2\\\",\\\"name\\\":\\\"Action 2\\\",\\\"description\\\":\\\"Increase value\\\"}]\")\n\n(instance a_matrix Matrix)\n(name a_matrix \"Observation Likelihood Matrix\")\n(symbol a_matrix \"A\")\n(dimensions a_matrix \"[3,5]\")\n(description a_matrix \"Maps hidden states to observations (likelihood mapping)\")\n(matrix_type a_matrix \"likelihood\")\n(matrix_data a_matrix \"[[0.8,0.3,0.1,0,0],[0.2,0.6,0.7,0.3,0.1],[0,0.1,0.2,0.7,0.9]]\")\n(precision a_matrix 0.9)\n(column_labels a_matrix \"[\\\"s1\\\",\\\"s2\\\",\\\"s3\\\",\\\"s4\\\",\\\"s5\\\"]\")\n(row_labels a_matrix \"[\\\"o1\\\",\\\"o2\\\",\\\"o3\\\"]\")\n\n(instance b_matrix Matrix)\n(name b_matrix \"State Transition Matrix\")\n(symbol b_matrix \"B\")\n(dimensions b_matrix \"[5,5,2]\")\n(description b_matrix \"Defines the dynamics of state transitions based on actions\")\n(matrix_type b_matrix \"transition\")\n(matrix_data b_matrix \"[[[0.9,0.2,0,0,0],[0.1,0.7,0.2,0,0],[0,0.1,0.7,0.2,0],[0,0,0.1,0.7,0.1],[0,0,0,0.1,0.9]],[[0.9,0.1,0,0,0],[0.1,0.7,0.1,0,0],[0,0.2,0.7,0.1,0],[0,0,0.2,0.7,0.1],[0,0,0,0.2,0.9]]]\")\n(action_labels b_matrix \"[\\\"a1\\\",\\\"a2\\\"]\")\n(column_labels b_matrix \"[\\\"s1\\\",\\\"s2\\\",\\\"s3\\\",\\\"s4\\\",\\\"s5\\\"]\")\n(row_labels b_matrix \"[\\\"s1\\\",\\\"s2\\\",\\\"s3\\\",\\\"s4\\\",\\\"s5\\\"]\")\n\n(instance c_matrix Matrix)\n(name c_matrix \"Preference Matrix\")\n(symbol c_matrix \"C\")\n(dimensions c_matrix \"[3,1]\")\n(description c_matrix \"Specifies the agent preferences over observations (as log probabilities)\")\n(matrix_type c_matrix \"preference\")\n(matrix_data c_matrix \"[[-3],[0],[3]]\")\n(row_labels c_matrix \"[\\\"o1\\\",\\\"o2\\\",\\\"o3\\\"]\")\n(precision c_matrix 1)\n\n(instance d_matrix Matrix)\n(name d_matrix \"Initial State Prior\")\n(symbol d_matrix \"D\")\n(dimensions d_matrix \"[5,1]\")\n(description d_matrix \"Defines the prior distribution over initial states\")\n(matrix_type d_matrix \"prior\")\n(matrix_data d_matrix \"[[0.2],[0.2],[0.4],[0.1],[0.1]]\")\n(row_labels d_matrix \"[\\\"s1\\\",\\\"s2\\\",\\\"s3\\\",\\\"s4\\\",\\\"s5\\\"]\")\n\n(instance e_matrix Matrix)\n(name e_matrix \"Policy Prior\")\n(symbol e_matrix \"E\")\n(dimensions e_matrix \"[2,1]\")\n(description e_matrix \"Defines the prior distribution over policies/actions\")\n(matrix_type e_matrix \"policy_prior\")\n(matrix_data e_matrix \"[[0.5],[0.5]]\")\n(row_labels e_matrix \"[\\\"a1\\\",\\\"a2\\\"]\")\n\n;; Relationships\n(includes pomdp_model observation_space)\n\n(includes pomdp_model state_space)\n\n(includes pomdp_model action_space)\n\n(includes pomdp_model a_matrix)\n\n(includes pomdp_model b_matrix)\n\n(includes pomdp_model c_matrix)\n\n(includes pomdp_model d_matrix)\n\n(includes pomdp_model e_matrix)\n\n(maps_from a_matrix observation_space)\n\n(maps_to a_matrix state_space)\n\n(maps_from b_matrix state_space)\n\n(maps_to b_matrix state_space)\n\n(conditioned_on b_matrix action_space)\n\n(evaluates c_matrix observation_space)\n\n(distributes_over d_matrix state_space)\n\n(distributes_over e_matrix action_space)\n\n",
  "bayesian": {
    "json": "{\"metadata\":{\"type\":\"Generic\",\"timestamp\":\"2025-03-09T18:52:14.758Z\"},\"nodes\":[{\"id\":\"system_state\",\"type\":\"discrete\",\"outcomes\":[\"good\",\"fair\",\"poor\"],\"comment\":\"Overall system state\"}],\"edges\":[]}"
  },
  "visualization": {
    "svg": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"800\" height=\"600\" viewBox=\"0 0 800 600\">\n        <style>\n          .node circle { stroke: #fff; stroke-width: 1.5px; }\n          .node text { font-family: Arial; font-size: 12px; }\n        </style>\n        <rect width=\"100%\" height=\"100%\" fill=\"#f8f9fa\"/>\n        <g class=\"nodes\">\n          <g class=\"node\" transform=\"translate(50,50)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Active Inference POMDP Model</text>\n            </g><g class=\"node\" transform=\"translate(200,50)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Observation Space</text>\n            </g><g class=\"node\" transform=\"translate(350,50)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Latent State Space</text>\n            </g><g class=\"node\" transform=\"translate(500,50)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Action Space</text>\n            </g><g class=\"node\" transform=\"translate(650,50)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Observation Likelihood Matrix</text>\n            </g><g class=\"node\" transform=\"translate(50,150)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">State Transition Matrix</text>\n            </g><g class=\"node\" transform=\"translate(200,150)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Preference Matrix</text>\n            </g><g class=\"node\" transform=\"translate(350,150)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Initial State Prior</text>\n            </g><g class=\"node\" transform=\"translate(500,150)\">\n              <circle r=\"8\" fill=\"#4285F4\"/>\n              <text dx=\"12\" dy=\".35em\">Policy Prior</text>\n            </g>\n        </g>\n      </svg>"
  }
}